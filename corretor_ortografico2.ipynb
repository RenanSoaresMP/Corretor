{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "corretor_ortografico2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOEsN2qNtrZ35lCnN6dVyDe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RenanSoaresMP/Corretor/blob/Melhorias/corretor_ortografico2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Criando lista com palavras corretas como referência"
      ],
      "metadata": {
        "id": "PL4JX6bE7-Kh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "PdtvpeyC1jYr"
      },
      "outputs": [],
      "source": [
        "with open(\"artigos.txt\", \"r\") as f:\n",
        "    artigos = f.read()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenização\n",
        "texto_exemplo = 'Olá, tudo bem?'\n",
        "import nltk \n",
        "nltk.download('punkt')\n",
        "palavras_separadas = nltk.tokenize.word_tokenize(texto_exemplo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAWZkDtO1zim",
        "outputId": "35bd9e9e-17fb-432d-c6d3-df5f1f622ffd"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(palavras_separadas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Valkb0R2-ud",
        "outputId": "46b6cbd3-3529-44e3-e3df-b32e5cfb3fea"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Olá', ',', 'tudo', 'bem', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Retornando apenas as palavras\n",
        "def separa_palavras(lista_tokens):\n",
        "    lista_palavras = []\n",
        "    for token in lista_tokens:\n",
        "        if token.isalpha():\n",
        "            lista_palavras.append(token)\n",
        "    return lista_palavras\n",
        "\n",
        "separa_palavras(palavras_separadas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eobTkqI3EiY",
        "outputId": "b250c9be-9fe6-425d-d0f2-bba253221fe4"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Olá', 'tudo', 'bem']"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lista_tokens = nltk.tokenize.word_tokenize(artigos)    #Tokenização do arquico artigos.txt\n",
        "lista_palavras = separa_palavras(lista_tokens)         #Retirando os sinais de pontuação \n",
        "print(f\"O número de palavras é {len(lista_palavras)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biYHsz7y4AC6",
        "outputId": "1748141f-95e3-4f4b-949a-e08f26585257"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O número de palavras é 393914\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalização da lista_palavras\n",
        "def normalizacao(lista_palavras):\n",
        "    lista_normalizada = []\n",
        "    for palavra in lista_palavras:\n",
        "        lista_normalizada.append(palavra.lower())\n",
        "    return lista_normalizada\n",
        "\n",
        "lista_normalizada = normalizacao(lista_palavras)\n",
        "print(lista_normalizada[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_eEFY0754F1",
        "outputId": "1b16a4a1-f7be-4f94-aeb1-6a6312872728"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['imagem', 'temos', 'a', 'seguinte', 'classe']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Removendo palavras iguais\n",
        "len(set(lista_normalizada))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0IyO8fD6WXl",
        "outputId": "3f88f40e-1355-41fb-b769-c5e3a50296a0"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17652"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4dJZt5Zi78T8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "palavra_exemplo = \"lgica\"\n",
        "\n",
        "def insere_letras(fatias):\n",
        "    novas_palavras = []\n",
        "    letras = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
        "    for E, D in fatias:\n",
        "        for letra in letras:\n",
        "            novas_palavras.append(E + letra + D)\n",
        "        return novas_palavras\n",
        "\n",
        "def deletando_caracteres(fatias):\n",
        "    novas_palavras = []\n",
        "    for E, D in fatias:\n",
        "        novas_palavras.append(E + D[1:])\n",
        "    return novas_palavras\n",
        "\n",
        "def troca_letra(fatias):\n",
        "    novas_palavras = []\n",
        "    letras = 'abcdefghijklmnopqrstuvwxyzáàãâéèêíìóòõôúùûç'\n",
        "    for E, D in fatias:\n",
        "        for letra in letras:\n",
        "            novas_palavras.append(E + letra + D[1:])\n",
        "    return novas_palavras\n",
        "\n",
        "def inverte_letra(fatias):\n",
        "    novas_palavras = []\n",
        "    for E, D in fatias:\n",
        "      if len(D) > 1:\n",
        "        novas_palavras.append(E + D[1] + D[0] + D[2:])\n",
        "    return novas_palavras\n",
        "\n",
        "\n",
        "def gerador_palavras(palavra):\n",
        "    fatias = []\n",
        "    for i in range(len(palavra)+1):\n",
        "        fatias.append((palavra[:i],palavra[i:]))      #gera as palavras fatiadas\n",
        "    palavras_geradas = insere_letras(fatias)          #teste na função insere_letras\n",
        "    palavras_geradas += deletando_caracteres(fatias)  #teste na função deletando_caracteres\n",
        "    palavras_geradas += troca_letra(fatias)           #teste na função troca_letra\n",
        "    palavras_geradas += inverte_letra(fatias)         #teste na função inverte_letra\n",
        "    return palavras_geradas\n",
        "\n",
        "palavras_geradas = gerador_palavras(palavra_exemplo)\n",
        "print(palavras_geradas)\n",
        "\n",
        "def corretor(palavra):\n",
        "    palavras_geradas = gerador_palavras(palavra)\n",
        "    palavra_correta = max(palavras_geradas, key=probabilidade)\n",
        "    return palavra_correta\n",
        "\n",
        "frequencia = nltk.FreqDist(lista_normalizada)\n",
        "total_palavras = len(lista_normalizada)\n",
        "frequencia.most_common(10)\n",
        "\n",
        "def probabilidade(palavra_gerada):\n",
        "    return frequencia[palavra_gerada]/total_palavras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yrs_-HJ5IQYs",
        "outputId": "94595f82-bf79-4cbe-b1fd-498dddd3b42f"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['algica', 'blgica', 'clgica', 'dlgica', 'elgica', 'flgica', 'glgica', 'hlgica', 'ilgica', 'jlgica', 'klgica', 'llgica', 'mlgica', 'nlgica', 'olgica', 'plgica', 'qlgica', 'rlgica', 'slgica', 'tlgica', 'ulgica', 'vlgica', 'wlgica', 'xlgica', 'ylgica', 'zlgica', 'àlgica', 'álgica', 'âlgica', 'ãlgica', 'èlgica', 'élgica', 'êlgica', 'ìlgica', 'ílgica', 'îlgica', 'òlgica', 'ólgica', 'ôlgica', 'õlgica', 'ùlgica', 'úlgica', 'ûlgica', 'çlgica', 'gica', 'lica', 'lgca', 'lgia', 'lgic', 'lgica', 'agica', 'bgica', 'cgica', 'dgica', 'egica', 'fgica', 'ggica', 'hgica', 'igica', 'jgica', 'kgica', 'lgica', 'mgica', 'ngica', 'ogica', 'pgica', 'qgica', 'rgica', 'sgica', 'tgica', 'ugica', 'vgica', 'wgica', 'xgica', 'ygica', 'zgica', 'ágica', 'àgica', 'ãgica', 'âgica', 'égica', 'ègica', 'êgica', 'ígica', 'ìgica', 'ógica', 'ògica', 'õgica', 'ôgica', 'úgica', 'ùgica', 'ûgica', 'çgica', 'laica', 'lbica', 'lcica', 'ldica', 'leica', 'lfica', 'lgica', 'lhica', 'liica', 'ljica', 'lkica', 'llica', 'lmica', 'lnica', 'loica', 'lpica', 'lqica', 'lrica', 'lsica', 'ltica', 'luica', 'lvica', 'lwica', 'lxica', 'lyica', 'lzica', 'láica', 'làica', 'lãica', 'lâica', 'léica', 'lèica', 'lêica', 'líica', 'lìica', 'lóica', 'lòica', 'lõica', 'lôica', 'lúica', 'lùica', 'lûica', 'lçica', 'lgaca', 'lgbca', 'lgcca', 'lgdca', 'lgeca', 'lgfca', 'lggca', 'lghca', 'lgica', 'lgjca', 'lgkca', 'lglca', 'lgmca', 'lgnca', 'lgoca', 'lgpca', 'lgqca', 'lgrca', 'lgsca', 'lgtca', 'lguca', 'lgvca', 'lgwca', 'lgxca', 'lgyca', 'lgzca', 'lgáca', 'lgàca', 'lgãca', 'lgâca', 'lgéca', 'lgèca', 'lgêca', 'lgíca', 'lgìca', 'lgóca', 'lgòca', 'lgõca', 'lgôca', 'lgúca', 'lgùca', 'lgûca', 'lgçca', 'lgiaa', 'lgiba', 'lgica', 'lgida', 'lgiea', 'lgifa', 'lgiga', 'lgiha', 'lgiia', 'lgija', 'lgika', 'lgila', 'lgima', 'lgina', 'lgioa', 'lgipa', 'lgiqa', 'lgira', 'lgisa', 'lgita', 'lgiua', 'lgiva', 'lgiwa', 'lgixa', 'lgiya', 'lgiza', 'lgiáa', 'lgiàa', 'lgiãa', 'lgiâa', 'lgiéa', 'lgièa', 'lgiêa', 'lgiía', 'lgiìa', 'lgióa', 'lgiòa', 'lgiõa', 'lgiôa', 'lgiúa', 'lgiùa', 'lgiûa', 'lgiça', 'lgica', 'lgicb', 'lgicc', 'lgicd', 'lgice', 'lgicf', 'lgicg', 'lgich', 'lgici', 'lgicj', 'lgick', 'lgicl', 'lgicm', 'lgicn', 'lgico', 'lgicp', 'lgicq', 'lgicr', 'lgics', 'lgict', 'lgicu', 'lgicv', 'lgicw', 'lgicx', 'lgicy', 'lgicz', 'lgicá', 'lgicà', 'lgicã', 'lgicâ', 'lgicé', 'lgicè', 'lgicê', 'lgicí', 'lgicì', 'lgicó', 'lgicò', 'lgicõ', 'lgicô', 'lgicú', 'lgicù', 'lgicû', 'lgicç', 'lgicaa', 'lgicab', 'lgicac', 'lgicad', 'lgicae', 'lgicaf', 'lgicag', 'lgicah', 'lgicai', 'lgicaj', 'lgicak', 'lgical', 'lgicam', 'lgican', 'lgicao', 'lgicap', 'lgicaq', 'lgicar', 'lgicas', 'lgicat', 'lgicau', 'lgicav', 'lgicaw', 'lgicax', 'lgicay', 'lgicaz', 'lgicaá', 'lgicaà', 'lgicaã', 'lgicaâ', 'lgicaé', 'lgicaè', 'lgicaê', 'lgicaí', 'lgicaì', 'lgicaó', 'lgicaò', 'lgicaõ', 'lgicaô', 'lgicaú', 'lgicaù', 'lgicaû', 'lgicaç', 'glica', 'ligca', 'lgcia', 'lgiac']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Criando a lista de testes para avaliar a taxa de acertos do corretor\n",
        "def cria_dados_teste(nome_arquivo):      \n",
        "    lista_palavras_teste = []\n",
        "    f = open(nome_arquivo, \"r\")\n",
        "    for linha in f:\n",
        "        correta, errada = linha.split()\n",
        "        lista_palavras_teste.append((correta, errada))\n",
        "    f.close()\n",
        "    return lista_palavras_teste\n",
        "\n",
        "lista_teste = cria_dados_teste(\"palavras.txt\")\n",
        "#lista_teste"
      ],
      "metadata": {
        "id": "-CBqlS49EzMF"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Criando o avaliador que nos fornece a taxa de acertos\n",
        "def avaliador (testes):\n",
        "    numero_palavras = len(testes)\n",
        "    acertou = 0\n",
        "    for correta, errada in testes:\n",
        "        palavra_corrigida = corretor(errada)\n",
        "        if palavra_corrigida == correta:\n",
        "            acertou += 1\n",
        "    taxa_acerto = round(acertou*100/numero_palavras, 2)\n",
        "    print(f\"{taxa_acerto}% de {numero_palavras} palavras\")\n",
        "\n",
        "avaliador(lista_teste)"
      ],
      "metadata": {
        "id": "g7UTtGrCTedW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b2c4d68-3a22-435a-aa44-7aead3cb0011"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "75.27% de 186 palavras\n"
          ]
        }
      ]
    }
  ]
}